2019-02-04 18:11:28.297562: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Load dataset
sentenceTrain:  (460, 55)
positionTrain1:  (460, 55)
yTrain:  (460,)
sentenceTest:  (98, 55)
positionTest1:  (98, 55)
yTest:  (98,)
Embeddings:  (1619, 300)
(?, 55, 128)
(?, 55, 1)
(?, 55, 1)
(?, 1, 128)
(?, 1, 128)
(?, ?)
(?, 2)
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
words_input (InputLayer)        (None, 55)           0                                            
__________________________________________________________________________________________________
distance1_input (InputLayer)    (None, 55)           0                                            
__________________________________________________________________________________________________
distance2_input (InputLayer)    (None, 55)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 55, 300)      485700      words_input[0][0]                
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 55, 100)      6400        distance1_input[0][0]            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 55, 100)      6400        distance2_input[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 55, 500)      0           embedding_1[0][0]                
                                                                 embedding_2[0][0]                
                                                                 embedding_3[0][0]                
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 55, 128)      128128      concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 55, 1)        129         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 55, 1)        0           dense_1[0][0]                    
__________________________________________________________________________________________________
dot_1 (Dot)                     (None, 1, 128)       0           activation_1[0][0]               
                                                                 conv1d_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 1, 128)       0           dot_1[0][0]                      
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 128)          0           dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 256)          33024       reshape_1[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 100)          25700       dense_2[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 2)            202         dense_3[0][0]                    
==================================================================================================
Total params: 685,683
Trainable params: 685,683
Non-trainable params: 0
__________________________________________________________________________________________________
Start training

Epoch	1

Epoch 1/1

 32/460 [=>............................] - ETA: 10s - loss: 1.1194 - acc: 0.5000
 64/460 [===>..........................] - ETA: 5s - loss: 1.6186 - acc: 0.5156 
128/460 [=======>......................] - ETA: 2s - loss: 1.4725 - acc: 0.5469
192/460 [===========>..................] - ETA: 1s - loss: 1.4475 - acc: 0.5208
256/460 [===============>..............] - ETA: 0s - loss: 1.4794 - acc: 0.5156
320/460 [===================>..........] - ETA: 0s - loss: 1.3710 - acc: 0.5312
384/460 [========================>.....] - ETA: 0s - loss: 1.3189 - acc: 0.5208
448/460 [============================>.] - ETA: 0s - loss: 1.2658 - acc: 0.5223
460/460 [==============================] - 1s 3ms/step - loss: 1.2594 - acc: 0.5217
Accuracy: 0.5102 (max: 0.5102)
Non-other Macro-Averaged F1: 0.3556 (max: 0.3556)


Epoch	2

Epoch 1/1

 32/460 [=>............................] - ETA: 0s - loss: 1.1410 - acc: 0.4688
 96/460 [=====>........................] - ETA: 0s - loss: 0.8495 - acc: 0.5521
160/460 [=========>....................] - ETA: 0s - loss: 0.7763 - acc: 0.5625
224/460 [=============>................] - ETA: 0s - loss: 0.8040 - acc: 0.5759
288/460 [=================>............] - ETA: 0s - loss: 0.7755 - acc: 0.5938
352/460 [=====================>........] - ETA: 0s - loss: 0.7717 - acc: 0.5966
416/460 [==========================>...] - ETA: 0s - loss: 0.7709 - acc: 0.6058
460/460 [==============================] - 0s 899us/step - loss: 0.7859 - acc: 0.6000
Accuracy: 0.5612 (max: 0.5612)
Non-other Macro-Averaged F1: 0.4681 (max: 0.4681)


Epoch	3

Epoch 1/1

 32/460 [=>............................] - ETA: 0s - loss: 0.6433 - acc: 0.6562
128/460 [=======>......................] - ETA: 0s - loss: 0.6870 - acc: 0.5781
192/460 [===========>..................] - ETA: 0s - loss: 0.7025 - acc: 0.5885
288/460 [=================>............] - ETA: 0s - loss: 0.6877 - acc: 0.6354
384/460 [========================>.....] - ETA: 0s - loss: 0.6847 - acc: 0.6198
448/460 [============================>.] - ETA: 0s - loss: 0.6551 - acc: 0.6429
460/460 [==============================] - 0s 839us/step - loss: 0.6563 - acc: 0.6413
Accuracy: 0.6429 (max: 0.6429)
Non-other Macro-Averaged F1: 0.6086 (max: 0.6086)


Epoch	4

Epoch 1/1

 32/460 [=>............................] - ETA: 0s - loss: 0.6248 - acc: 0.6562
 96/460 [=====>........................] - ETA: 0s - loss: 0.6077 - acc: 0.7083
160/460 [=========>....................] - ETA: 0s - loss: 0.5739 - acc: 0.7312
224/460 [=============>................] - ETA: 0s - loss: 0.5437 - acc: 0.7455
288/460 [=================>............] - ETA: 0s - loss: 0.5346 - acc: 0.7500
352/460 [=====================>........] - ETA: 0s - loss: 0.5362 - acc: 0.7472
416/460 [==========================>...] - ETA: 0s - loss: 0.5230 - acc: 0.7620
460/460 [==============================] - 0s 1ms/step - loss: 0.5133 - acc: 0.7674
Accuracy: 0.7347 (max: 0.7347)
Non-other Macro-Averaged F1: 0.7292 (max: 0.7292)


Epoch	5

Epoch 1/1

 32/460 [=>............................] - ETA: 0s - loss: 0.3794 - acc: 0.8125
 96/460 [=====>........................] - ETA: 0s - loss: 0.4809 - acc: 0.6979
160/460 [=========>....................] - ETA: 0s - loss: 0.4424 - acc: 0.7688
224/460 [=============>................] - ETA: 0s - loss: 0.4187 - acc: 0.7857
288/460 [=================>............] - ETA: 0s - loss: 0.4276 - acc: 0.7917
384/460 [========================>.....] - ETA: 0s - loss: 0.4110 - acc: 0.7969
448/460 [============================>.] - ETA: 0s - loss: 0.4110 - acc: 0.8013
460/460 [==============================] - 0s 864us/step - loss: 0.4068 - acc: 0.8065
Accuracy: 0.8469 (max: 0.8469)
Non-other Macro-Averaged F1: 0.8465 (max: 0.8465)


Epoch	6

Epoch 1/1

 32/460 [=>............................] - ETA: 0s - loss: 0.2954 - acc: 0.8750
 96/460 [=====>........................] - ETA: 0s - loss: 0.3962 - acc: 0.8333
160/460 [=========>....................] - ETA: 0s - loss: 0.3569 - acc: 0.8375
224/460 [=============>................] - ETA: 0s - loss: 0.3309 - acc: 0.8527
288/460 [=================>............] - ETA: 0s - loss: 0.3098 - acc: 0.8611
352/460 [=====================>........] - ETA: 0s - loss: 0.3115 - acc: 0.8665
416/460 [==========================>...] - ETA: 0s - loss: 0.3146 - acc: 0.8654
460/460 [==============================] - 0s 855us/step - loss: 0.3074 - acc: 0.8674
Accuracy: 0.7857 (max: 0.8469)
Non-other Macro-Averaged F1: 0.7857 (max: 0.8465)


Epoch	7

Epoch 1/1

 32/460 [=>............................] - ETA: 0s - loss: 0.1972 - acc: 0.9688
 96/460 [=====>........................] - ETA: 0s - loss: 0.1889 - acc: 0.9375
160/460 [=========>....................] - ETA: 0s - loss: 0.2102 - acc: 0.9187
256/460 [===============>..............] - ETA: 0s - loss: 0.2552 - acc: 0.9102
320/460 [===================>..........] - ETA: 0s - loss: 0.2273 - acc: 0.9250
384/460 [========================>.....] - ETA: 0s - loss: 0.2579 - acc: 0.9089
448/460 [============================>.] - ETA: 0s - loss: 0.2512 - acc: 0.9062
460/460 [==============================] - 0s 851us/step - loss: 0.2508 - acc: 0.9065
Accuracy: 0.8673 (max: 0.8673)
Non-other Macro-Averaged F1: 0.8662 (max: 0.8662)


Epoch	8

Epoch 1/1

 32/460 [=>............................] - ETA: 0s - loss: 0.1384 - acc: 0.9375
 96/460 [=====>........................] - ETA: 0s - loss: 0.1291 - acc: 0.9583
160/460 [=========>....................] - ETA: 0s - loss: 0.1258 - acc: 0.9625
224/460 [=============>................] - ETA: 0s - loss: 0.1403 - acc: 0.9509
288/460 [=================>............] - ETA: 0s - loss: 0.1384 - acc: 0.9514
352/460 [=====================>........] - ETA: 0s - loss: 0.1339 - acc: 0.9545
416/460 [==========================>...] - ETA: 0s - loss: 0.1358 - acc: 0.9543
460/460 [==============================] - 0s 854us/step - loss: 0.1453 - acc: 0.9543
Accuracy: 0.8673 (max: 0.8673)
Non-other Macro-Averaged F1: 0.8667 (max: 0.8667)


Epoch	9

Epoch 1/1

 32/460 [=>............................] - ETA: 0s - loss: 0.1148 - acc: 0.9688
 96/460 [=====>........................] - ETA: 0s - loss: 0.0785 - acc: 0.9792
160/460 [=========>....................] - ETA: 0s - loss: 0.0978 - acc: 0.9688
224/460 [=============>................] - ETA: 0s - loss: 0.0933 - acc: 0.9732
288/460 [=================>............] - ETA: 0s - loss: 0.1121 - acc: 0.9688
352/460 [=====================>........] - ETA: 0s - loss: 0.1065 - acc: 0.9716
416/460 [==========================>...] - ETA: 0s - loss: 0.1184 - acc: 0.9712
460/460 [==============================] - 0s 874us/step - loss: 0.1149 - acc: 0.9717
Accuracy: 0.8367 (max: 0.8673)
Non-other Macro-Averaged F1: 0.8367 (max: 0.8667)


Epoch	10

Epoch 1/1

 32/460 [=>............................] - ETA: 0s - loss: 0.0557 - acc: 1.0000
 96/460 [=====>........................] - ETA: 0s - loss: 0.0852 - acc: 0.9583
160/460 [=========>....................] - ETA: 0s - loss: 0.1302 - acc: 0.9437
224/460 [=============>................] - ETA: 0s - loss: 0.1267 - acc: 0.9464
288/460 [=================>............] - ETA: 0s - loss: 0.1341 - acc: 0.9410
352/460 [=====================>........] - ETA: 0s - loss: 0.1453 - acc: 0.9318
448/460 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9420
460/460 [==============================] - 0s 867us/step - loss: 0.1300 - acc: 0.9413
/home/sriram/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Accuracy: 0.8061 (max: 0.8673)
Non-other Macro-Averaged F1: 0.8051 (max: 0.8667)

