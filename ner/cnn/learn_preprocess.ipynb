{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "if (sys.version_info > (3, 0)):\n",
    "    import pickle as pkl\n",
    "else: #Python 2.7 imports\n",
    "    import cPickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputFilePath = 'pkl/sem-relations.pkl.gz'\n",
    "\n",
    "outputFilePath='ADE-corpus/'\n",
    "#We download English word embeddings from here https://www.cs.york.ac.uk/nlp/extvec/\n",
    "embeddingsPath = 'embeddings/wiki_extvec.gz'\n",
    "\n",
    "\n",
    "folder = 'ADE-corpus/'\n",
    "files = [folder+'train.txt', folder+'test.txt']\n",
    "\n",
    "#Mapping of the labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsMapping={'DRUG-DOSE':0,'DRUG-AE':1}\n",
    "\n",
    "\n",
    "words = {}\n",
    "maxSentenceLen = [0,0]\n",
    "\n",
    "\n",
    "distanceMapping = {'PADDING': 0, 'LowerMin': 1, 'GreaterMax': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "minDistance = -30\n",
    "maxDistance = 30\n",
    "for dis in range(minDistance,maxDistance+1):\n",
    "    distanceMapping[dis] = len(distanceMapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distanceMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMatrices(file, word2Idx, maxSentenceLen=100):\n",
    "    \"\"\"Creates matrices for the events and sentence for the given file\"\"\"\n",
    "    labels = []\n",
    "    positionMatrix1 = []\n",
    "    positionMatrix2 = []\n",
    "    tokenMatrix = []\n",
    "    \n",
    "    for line in open(file):\n",
    "        splits = line.strip().split('\\t')\n",
    "        \n",
    "        label = splits[0]\n",
    "        pos1 = splits[1]\n",
    "        pos2 = splits[2]\n",
    "        sentence = splits[3]\n",
    "        tokens = sentence.split(\" \")\n",
    "        \n",
    "       \n",
    "\n",
    "        \n",
    "        tokenIds = np.zeros(maxSentenceLen)\n",
    "        positionValues1 = np.zeros(maxSentenceLen)\n",
    "        positionValues2 = np.zeros(maxSentenceLen)\n",
    "        \n",
    "        for idx in range(0, min(maxSentenceLen, len(tokens))):\n",
    "            tokenIds[idx] = getWordIdx(tokens[idx], word2Idx)\n",
    "            \n",
    "            distance1 = idx - int(pos1)\n",
    "            distance2 = idx - int(pos2)\n",
    "            \n",
    "            if distance1 in distanceMapping:\n",
    "                positionValues1[idx] = distanceMapping[distance1]\n",
    "            elif distance1 <= minDistance:\n",
    "                positionValues1[idx] = distanceMapping['LowerMin']\n",
    "            else:\n",
    "                positionValues1[idx] = distanceMapping['GreaterMax']\n",
    "                \n",
    "            if distance2 in distanceMapping:\n",
    "                positionValues2[idx] = distanceMapping[distance2]\n",
    "            elif distance2 <= minDistance:\n",
    "                positionValues2[idx] = distanceMapping['LowerMin']\n",
    "            else:\n",
    "                positionValues2[idx] = distanceMapping['GreaterMax']\n",
    "            \n",
    "        tokenMatrix.append(tokenIds)\n",
    "        positionMatrix1.append(positionValues1)\n",
    "        positionMatrix2.append(positionValues2)\n",
    "        \n",
    "        labels.append(labelsMapping[label])\n",
    "        \n",
    "\n",
    "    \n",
    "    return np.array(labels, dtype='int32'), np.array(tokenMatrix, dtype='int32'), np.array(positionMatrix1, dtype='int32'), np.array(positionMatrix2, dtype='int32'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordIdx(token, word2Idx): \n",
    "    \"\"\"Returns from the word2Idex table the word index for a given token\"\"\"       \n",
    "    if token in word2Idx:\n",
    "        return word2Idx[token]\n",
    "    elif token.lower() in word2Idx:\n",
    "        return word2Idx[token.lower()]\n",
    "    \n",
    "    return word2Idx[\"UNKNOWN_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileIdx in range(len(files)):\n",
    "    file = files[fileIdx]\n",
    "    for line in open(file):\n",
    "        splits = line.strip().split('\\t')\n",
    "        \n",
    "        label = splits[0]\n",
    "        \n",
    "        \n",
    "        sentence = splits[3]        \n",
    "        tokens = sentence.split(\" \")\n",
    "        maxSentenceLen[fileIdx] = max(maxSentenceLen[fileIdx], len(tokens))\n",
    "        for token in tokens:\n",
    "            words[token.lower()] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence Lengths:  [55, 46]\n"
     ]
    }
   ],
   "source": [
    "print(\"Max Sentence Lengths: \", maxSentenceLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Read in word embeddings ::\n",
    "# :: Read in word embeddings ::\n",
    "word2Idx = {}\n",
    "wordEmbeddings = []\n",
    "\n",
    "# :: Downloads the embeddings from the York webserver ::\n",
    "if not os.path.isfile(embeddingsPath):\n",
    "    basename = os.path.basename(embeddingsPath)\n",
    "    if basename == 'wiki_extvec.gz':\n",
    "           print(\"Start downloading word embeddings for English using wget ...\")\n",
    "           #os.system(\"wget https://www.cs.york.ac.uk/nlp/extvec/\"+basename+\" -P embeddings/\")\n",
    "           os.system(\"wget https://public.ukp.informatik.tu-darmstadt.de/reimers/2017_english_embeddings/\"+basename+\" -P embeddings/\")\n",
    "    else:\n",
    "        print(embeddingsPath, \"does not exist. Please provide pre-trained embeddings\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Load the pre-trained embeddings file ::\n",
    "fEmbeddings = gzip.open(embeddingsPath, \"r\") if embeddingsPath.endswith('.gz') else open(embeddingsPath, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-trained embeddings file\n"
     ]
    }
   ],
   "source": [
    "print(\"Load pre-trained embeddings file\")\n",
    "for line in fEmbeddings:\n",
    "    split = line.decode('utf-8').strip().split(\" \")\n",
    "    word = split[0]\n",
    "    \n",
    "    if len(word2Idx) == 0: #Add padding+unknown\n",
    "        word2Idx[\"PADDING_TOKEN\"] = len(word2Idx)\n",
    "        vector = np.zeros(len(split)-1) #Zero vector vor 'PADDING' word\n",
    "        wordEmbeddings.append(vector)\n",
    "        \n",
    "        word2Idx[\"UNKNOWN_TOKEN\"] = len(word2Idx)\n",
    "        vector = np.random.uniform(-0.25, 0.25, len(split)-1)\n",
    "        wordEmbeddings.append(vector)\n",
    "\n",
    "    if word.lower() in words:\n",
    "        vector = np.array([float(num) for num in split[1:]])\n",
    "        wordEmbeddings.append(vector)\n",
    "        word2Idx[word] = len(word2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
